{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLBox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author's description:\n",
    "\n",
    "MLBox is a powerful Automated Machine Learning python library. It provides the following features:\n",
    "\n",
    "* Fast reading and distributed data preprocessing/cleaning/formatting\n",
    "* Highly robust feature selection and leak detection\n",
    "* Accurate hyper-parameter optimization in high-dimensional space\n",
    "* State-of-the art predictive models for classification and regression (Deep Learning, Stacking, LightGBM,...)\n",
    "* Prediction with models interpretation\n",
    "\n",
    "#### Useful links:\n",
    "\n",
    "[home](https://pypi.org/project/mlbox/),\n",
    "[tutorial](https://www.analyticsvidhya.com/blog/2017/07/mlbox-library-automated-machine-learning/),\n",
    "[manual](https://mlbox.readthedocs.io/en/latest/),\n",
    "[git](https://github.com/AxeldeRomblay/MLBox),\n",
    "[more examples](https://mlbox.readthedocs.io/en/latest/introduction.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import\n",
    "\n",
    "Note that we use the subprocess function instead of the jupyter **!** method of running bash commands. Domino can run these notebooks as [jobs](https://support.dominodatalab.com/hc/en-us/articles/360023696651-Jobs) (batch or scheduled) which turns your ipython notebook into an executable script file! All you have to do is ensure the code can be executed in a .py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jsonschema==2.6\n",
      "  Downloading jsonschema-2.6.0-py2.py3-none-any.whl (39 kB)\n",
      "Installing collected packages: jsonschema\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 3.2.0\n",
      "    Uninstalling jsonschema-3.2.0:\n",
      "      Successfully uninstalled jsonschema-3.2.0\n",
      "Successfully installed jsonschema-3.0.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "#get the right version of jsonschema\n",
    "completed = subprocess.run(['sudo', 'pip', 'install', 'jsonschema==2.6'], \\\n",
    "                           stdout=subprocess.PIPE,)\n",
    "print(completed.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlbox\n",
      "  Downloading mlbox-0.8.2.tar.gz (30 kB)\n",
      "Collecting numpy==1.17.0\n",
      "  Downloading numpy-1.17.0-cp36-cp36m-manylinux1_x86_64.whl (20.4 MB)\n",
      "Collecting scipy==1.3.0\n",
      "  Downloading scipy-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (25.2 MB)\n",
      "Collecting matplotlib==3.0.3\n",
      "  Downloading matplotlib-3.0.3-cp36-cp36m-manylinux1_x86_64.whl (13.0 MB)\n",
      "Collecting hyperopt==0.1.2\n",
      "  Downloading hyperopt-0.1.2-py3-none-any.whl (115 kB)\n",
      "Collecting Keras==2.2.4\n",
      "  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
      "Collecting pandas==0.25.0\n",
      "  Downloading pandas-0.25.0-cp36-cp36m-manylinux1_x86_64.whl (10.5 MB)\n",
      "Collecting joblib==0.13.2\n",
      "  Downloading joblib-0.13.2-py2.py3-none-any.whl (278 kB)\n",
      "Requirement already satisfied: scikit-learn==0.21.3 in /usr/local/anaconda/lib/python3.6/site-packages (from mlbox) (0.21.3)\n",
      "Collecting tensorflow==1.14.0\n",
      "  Downloading tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2 MB)\n",
      "Collecting lightgbm==2.2.3\n",
      "  Downloading lightgbm-2.2.3-py2.py3-none-manylinux1_x86_64.whl (1.2 MB)\n",
      "Collecting tables==3.5.2\n",
      "  Downloading tables-3.5.2-cp36-cp36m-manylinux1_x86_64.whl (4.3 MB)\n",
      "Collecting xlrd==1.2.0\n",
      "  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/anaconda/lib/python3.6/site-packages (from matplotlib==3.0.3->mlbox) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/anaconda/lib/python3.6/site-packages (from matplotlib==3.0.3->mlbox) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/anaconda/lib/python3.6/site-packages (from matplotlib==3.0.3->mlbox) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/anaconda/lib/python3.6/site-packages (from matplotlib==3.0.3->mlbox) (1.0.1)\n",
      "Collecting pymongo\n",
      "  Downloading pymongo-3.10.1-cp36-cp36m-manylinux2014_x86_64.whl (460 kB)\n",
      "Requirement already satisfied: six in /usr/local/anaconda/lib/python3.6/site-packages (from hyperopt==0.1.2->mlbox) (1.14.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/anaconda/lib/python3.6/site-packages (from hyperopt==0.1.2->mlbox) (4.35.0)\n",
      "Requirement already satisfied: networkx in /usr/local/anaconda/lib/python3.6/site-packages (from hyperopt==0.1.2->mlbox) (2.1)\n",
      "Requirement already satisfied: future in /usr/local/anaconda/lib/python3.6/site-packages (from hyperopt==0.1.2->mlbox) (0.17.1)\n",
      "Requirement already satisfied: h5py in /usr/local/anaconda/lib/python3.6/site-packages (from Keras==2.2.4->mlbox) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/anaconda/lib/python3.6/site-packages (from Keras==2.2.4->mlbox) (5.1.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/anaconda/lib/python3.6/site-packages (from Keras==2.2.4->mlbox) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/anaconda/lib/python3.6/site-packages (from Keras==2.2.4->mlbox) (1.0.8)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/anaconda/lib/python3.6/site-packages (from pandas==0.25.0->mlbox) (2018.4)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/anaconda/lib/python3.6/site-packages (from tensorflow==1.14.0->mlbox) (1.14.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/anaconda/lib/python3.6/site-packages (from tensorflow==1.14.0->mlbox) (1.23.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/anaconda/lib/python3.6/site-packages (from tensorflow==1.14.0->mlbox) (0.8.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/anaconda/lib/python3.6/site-packages (from tensorflow==1.14.0->mlbox) (0.3.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/anaconda/lib/python3.6/site-packages (from tensorflow==1.14.0->mlbox) (1.11.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/anaconda/lib/python3.6/site-packages (from tensorflow==1.14.0->mlbox) (3.9.1)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/anaconda/lib/python3.6/site-packages (from tensorflow==1.14.0->mlbox) (1.14.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/anaconda/lib/python3.6/site-packages (from tensorflow==1.14.0->mlbox) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/anaconda/lib/python3.6/site-packages (from tensorflow==1.14.0->mlbox) (0.1.7)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/anaconda/lib/python3.6/site-packages (from tensorflow==1.14.0->mlbox) (0.33.6)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/anaconda/lib/python3.6/site-packages (from tensorflow==1.14.0->mlbox) (0.8.0)\n",
      "Requirement already satisfied: mock>=2.0 in /usr/local/anaconda/lib/python3.6/site-packages (from tables==3.5.2->mlbox) (4.0.1)\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/anaconda/lib/python3.6/site-packages (from tables==3.5.2->mlbox) (2.6.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/anaconda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib==3.0.3->mlbox) (45.1.0)\n",
      "Requirement already satisfied: decorator>=4.1.0 in /usr/local/anaconda/lib/python3.6/site-packages (from networkx->hyperopt==0.1.2->mlbox) (4.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/anaconda/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->mlbox) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/anaconda/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->mlbox) (0.15.6)\n",
      "Building wheels for collected packages: mlbox\n",
      "  Building wheel for mlbox (setup.py): started\n",
      "  Building wheel for mlbox (setup.py): finished with status 'done'\n",
      "  Created wheel for mlbox: filename=mlbox-0.8.2-py3-none-any.whl size=43823 sha256=a3f20673375c719a84beb09ab3722a2066ce1f9208e9283612a5c7a0cef3d383\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-kpq1kp9g/wheels/0a/be/5a/9699adc1e480550d41cde8a82038e9d50e98910c9d39e3c38c\n",
      "Successfully built mlbox\n",
      "Installing collected packages: numpy, scipy, matplotlib, pymongo, hyperopt, Keras, pandas, joblib, tensorflow, lightgbm, tables, xlrd, mlbox\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.17.2\n",
      "    Uninstalling numpy-1.17.2:\n",
      "      Successfully uninstalled numpy-1.17.2\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.3.1\n",
      "    Uninstalling scipy-1.3.1:\n",
      "      Successfully uninstalled scipy-1.3.1\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 2.2.2\n",
      "    Uninstalling matplotlib-2.2.2:\n",
      "      Successfully uninstalled matplotlib-2.2.2\n",
      "  Attempting uninstall: Keras\n",
      "    Found existing installation: Keras 2.3.0\n",
      "    Uninstalling Keras-2.3.0:\n",
      "      Successfully uninstalled Keras-2.3.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.0.1\n",
      "    Uninstalling pandas-1.0.1:\n",
      "      Successfully uninstalled pandas-1.0.1\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 0.14.1\n",
      "    Uninstalling joblib-0.14.1:\n",
      "      Successfully uninstalled joblib-0.14.1\n",
      "  Attempting uninstall: tables\n",
      "    Found existing installation: tables 3.4.3\n",
      "    Uninstalling tables-3.4.3:\n",
      "      Successfully uninstalled tables-3.4.3\n",
      "  Attempting uninstall: xlrd\n",
      "    Found existing installation: xlrd 1.1.0\n",
      "    Uninstalling xlrd-1.1.0:\n",
      "      Successfully uninstalled xlrd-1.1.0\n",
      "Successfully installed Keras-2.2.4 hyperopt-0.1.2 joblib-0.13.2 lightgbm-2.2.3 matplotlib-3.0.3 mlbox-0.8.2 numpy-1.17.0 pandas-0.25.0 pymongo-3.10.1 scipy-1.3.0 tables-3.5.2 tensorflow-1.14.0 xlrd-1.2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "completed = subprocess.run(['sudo', 'pip', 'install', 'mlbox'], \\\n",
    "                           stdout=subprocess.PIPE,)\n",
    "print(completed.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLBox main package contains 3 sub-packages : preprocessing, optimisation and prediction. Each one of them are respectively aimed at reading and preprocessing data, testing or optimising a wide range of learners and predicting the target on a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from mlbox.preprocessing import *\n",
    "from mlbox.optimisation import *\n",
    "from mlbox.prediction import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: mlbox\n",
      "Version: 0.8.2\n",
      "Summary: A powerful Automated Machine Learning python library.\n",
      "Home-page: https://github.com/AxeldeRomblay/mlbox\n",
      "Author: Axel ARONIO DE ROMBLAY\n",
      "Author-email: axelderomblay@gmail.com\n",
      "License: BSD-3\n",
      "Location: /usr/local/anaconda/lib/python3.6/site-packages\n",
      "Requires: hyperopt, tables, matplotlib, Keras, xlrd, numpy, joblib, tensorflow, pandas, scipy, scikit-learn, lightgbm\n",
      "Required-by: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#these notes were written for v 0.8.2\n",
    "completed = subprocess.run(['pip', 'show', 'mlbox'], \\\n",
    "                           stdout=subprocess.PIPE,)\n",
    "print(completed.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clearing the joblib file as recommended by MLBox authors\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#clearing the joblib file as recommended by MLBox authors\n",
    "completed = subprocess.run(['rm', '-rf', '../results/joblib'], \\\n",
    "                           stdout=subprocess.PIPE,)\n",
    "print('clearing the joblib file as recommended by MLBox authors')\n",
    "print(completed.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few pointers to keep in mind\n",
    "\n",
    "#### Importing data\n",
    "MLBox seems to prefer csv files. Otherwise you have to build your own dictionary. The dictionary structure is not overly complicated, but it introduces another chance for syntax or type errors. It might be wise to just use csv if saving and loading as csv is not too expensive.\n",
    "\n",
    "#### Train & test\n",
    "MLBox has a function called **train_test_split()**. It does not behave like the scikit-learn function of the same name. It can take a little getting use to. More on that below.\n",
    "\n",
    "#### Documentation\n",
    "MLBox documentation is high-level. Implementing in practice is more difficult. Could not find anything on deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the heart disease dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A note on importing data\n",
    "MLBox seems to prefer csv files. Otherwise you have to build your own dictionary. the dictionary structure is not complicated, but it introduces another chance for syntax or type error. It might be wise to just use csv if saving and loading as csv is not too expensive. csv files for the two datasets in this project are saved at **/mnt/data/raw/**\n",
    "\n",
    "#### A note on the train & test function\n",
    "MLBox has a function called **train_test_split()**. It does not behave like the scikit-learn function of the same name. It can take a little getting use to. It will help if you imagine that the authors of MLBox built it as a tool for Kaggle competitions. The training set needs to have **y** in it. The test set should not. You're on your own for accuracy against the test set as it is assumed you'll find out the real answers later with an external test set that is not part of the MLBox flow.\n",
    "\n",
    "#### A note on categorical fields\n",
    "MLBox tries to infer which columns are categorical. From what I can tell, it only looks at data type when doing so. This is a little annoying. Below, I had to take the extra step of mapping numeric values to text for each of the numeric/categorical columns so that MLBox will treat them as categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "/mnt/data/raw/heart.csv\n",
    "\n",
    "attribute documentation:\n",
    "      age: age in years\n",
    "      sex: sex (1 = male; 0 = female)\n",
    "      cp: chest pain type\n",
    "        -- Value 1: typical angina\n",
    "        -- Value 2: atypical angina\n",
    "        -- Value 3: non-anginal pain\n",
    "        -- Value 4: asymptomatic\n",
    "     trestbps: resting blood pressure (in mm Hg on admission to the \n",
    "        hospital)\n",
    "     chol: serum cholestoral in mg/dl\n",
    "     fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\n",
    "     restecg: resting electrocardiographic results\n",
    "        -- Value 0: normal\n",
    "        -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST \n",
    "                    elevation or depression of > 0.05 mV)\n",
    "        -- Value 2: showing probable or definite left ventricular hypertrophy\n",
    "                    by Estes' criteria\n",
    "     thalach: maximum heart rate achieved\n",
    "     exang: exercise induced angina (1 = yes; 0 = no)\n",
    "     oldpeak = ST depression induced by exercise relative to rest\n",
    "     slope: the slope of the peak exercise ST segment\n",
    "        -- Value 1: upsloping\n",
    "        -- Value 2: flat\n",
    "        -- Value 3: downsloping\n",
    "     ca: number of major vessels (0-3) colored by flourosopy\n",
    "     thal: \n",
    "         3 = normal; \n",
    "         6 = fixed defect; \n",
    "         7 = reversable defect\n",
    "     target: diagnosis of heart disease (angiographic disease status)\n",
    "        -- Value 0: < 50% diameter narrowing\n",
    "        -- Value 1: > 50% diameter narrowing\n",
    " '''\n",
    "\n",
    "#column names\n",
    "names = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang', \\\n",
    "         'oldpeak','slope','ca','thal','target']\n",
    "\n",
    "#load data from Domino project directory\n",
    "hd_data = pd.read_csv(\"/mnt/data/raw/heart.csv\", header=None, names=names)\n",
    "\n",
    "#in case some data comes in as string\n",
    "#convert to numeric and coerce errors to NaN\n",
    "for col in hd_data.columns:  # Iterate over chosen columns\n",
    "    hd_data[col] = pd.to_numeric(hd_data[col], errors='coerce')\n",
    "    \n",
    "#drop nulls\n",
    "#hd_data.dropna(inplace=True)\n",
    " \n",
    "#function to force non-numeric data for categorical columns\n",
    "def force_non_numeric(data, cols):\n",
    "    for c in cols:\n",
    "        data[c] = 'text_' + data[c].map(str)  \n",
    "    return data\n",
    "\n",
    "cat_cols = ['cp', 'restecg', 'slope', 'ca', 'thal']\n",
    "hd_data = force_non_numeric(hd_data, cat_cols)\n",
    "\n",
    "#create MLBox random samples for train and test\n",
    "hd_data_train = hd_data.sample(frac=0.7, replace=False, random_state=1)\n",
    "hd_data_test = hd_data[~hd_data.isin(hd_data_train)].dropna()\n",
    "hd_data_test_wo_target = hd_data_test.drop('target', axis=1)\n",
    "\n",
    "hd_data_train.to_csv('../data/processed/hd_data_train.csv', index=False)\n",
    "hd_data_test.to_csv('../data/processed/hd_data_test.csv', index=False)\n",
    "hd_data_test_wo_target.to_csv('../data/processed/hd_data_test_wo_target.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the list of paths to your train datasets and test datasets\n",
    "paths_hd = [\"../data/processed/hd_data_train.csv\", \\\n",
    "         \"../data/processed/hd_data_test_wo_target.csv\"]\n",
    "\n",
    "#the name of the target you try to predict (classification or regression)\n",
    "target_hd = \"target\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process the data\n",
    "\n",
    "Pass the training set (with the target) and the test set (without the target) to the **train_test_split()** funciton.\n",
    "\n",
    "Use **to_path** to keep your world organized. In my project I want everything in the results directory which is at the same level of the higherachy as the code directory and python is using the code directory as the home directory so we use **../results**.\n",
    "\n",
    "Note that after adding text to the numeric/categorical columns, they are now recognized as such. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reading csv : hd_data_train.csv ...\n",
      "cleaning data ...\n",
      "CPU time: 0.03611874580383301 seconds\n",
      "\n",
      "reading csv : hd_data_test_wo_target.csv ...\n",
      "cleaning data ...\n",
      "CPU time: 0.019336938858032227 seconds\n",
      "\n",
      "> Number of common features : 13\n",
      "\n",
      "gathering and crunching for train and test datasets ...\n",
      "reindexing for train and test datasets ...\n",
      "dropping training duplicates ...\n",
      "dropping constant variables on training set ...\n",
      "\n",
      "> Number of categorical features: 5\n",
      "> Number of numerical features: 8\n",
      "> Number of training samples : 212\n",
      "> Number of test samples : 92\n",
      "\n",
      "> You have no missing values on train set...\n",
      "\n",
      "> Task : classification\n",
      "1.0    110\n",
      "0.0    102\n",
      "Name: target, dtype: int64\n",
      "\n",
      "encoding target ...\n"
     ]
    }
   ],
   "source": [
    "#to read and preprocess your files\n",
    "mlb_data_hd = Reader(sep=\",\", to_path = '../results').train_test_split(paths_hd, target_hd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another processing note\n",
    "\n",
    "For some reasons I kept getting the first row as NA with the hd data. I couldn't find the source of the error so I just delete that bad row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb_data_hd['test'].drop(mlb_data_hd['test'].index[:1], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last processing note\n",
    "\n",
    "After building the dictionary, we processes the data as below with the nice MLBox feature of automatically droping ids and [drifting variables](https://github.com/AxeldeRomblay/MLBox/blob/master/docs/webinars/features.pdf) between train and test datasets. I have found that it does not automatically drop ids. The source code only seems to detect drift, which is not found in randomly generated id fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing drifts ...\n",
      "CPU time: 0.19828081130981445 seconds\n",
      "\n",
      "> Top 10 drifts\n",
      "\n",
      "('restecg', 0.10078388478716627)\n",
      "('trestbps', 0.0841012669765746)\n",
      "('age', 0.08366374988606329)\n",
      "('sex', 0.08146021328958164)\n",
      "('chol', 0.0789148664661381)\n",
      "('fbs', 0.06947862546714068)\n",
      "('slope', 0.04391577796007651)\n",
      "('exang', 0.04276273812779152)\n",
      "('thalach', 0.04074377905386939)\n",
      "('oldpeak', 0.02646294777139735)\n",
      "\n",
      "> Deleted variables : []\n",
      "> Drift coefficients dumped into directory : ../results\n"
     ]
    }
   ],
   "source": [
    "#drop IDs and useless columns\n",
    "mlb_data_hd = Drift_thresholder(to_path='../results').fit_transform(mlb_data_hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ca</th>\n",
       "      <th>chol</th>\n",
       "      <th>cp</th>\n",
       "      <th>exang</th>\n",
       "      <th>fbs</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>restecg</th>\n",
       "      <th>sex</th>\n",
       "      <th>slope</th>\n",
       "      <th>thal</th>\n",
       "      <th>thalach</th>\n",
       "      <th>trestbps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55.0</td>\n",
       "      <td>text_0.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>text_0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>text_1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text_0.0</td>\n",
       "      <td>text_3.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.0</td>\n",
       "      <td>text_4.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>text_1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>text_1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text_1.0</td>\n",
       "      <td>text_3.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.0</td>\n",
       "      <td>text_2.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>text_0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>text_0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text_2.0</td>\n",
       "      <td>text_3.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.0</td>\n",
       "      <td>text_2.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>text_0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>text_0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text_1.0</td>\n",
       "      <td>text_3.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.0</td>\n",
       "      <td>text_0.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>text_0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>text_0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text_1.0</td>\n",
       "      <td>text_3.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age        ca   chol        cp  exang  fbs  oldpeak   restecg  sex  \\\n",
       "0  55.0  text_0.0  217.0  text_0.0    1.0  0.0      5.6  text_1.0  1.0   \n",
       "1  58.0  text_4.0  220.0  text_1.0    0.0  0.0      0.4  text_1.0  1.0   \n",
       "2  48.0  text_2.0  256.0  text_0.0    1.0  1.0      0.0  text_0.0  1.0   \n",
       "3  60.0  text_2.0  206.0  text_0.0    1.0  0.0      2.4  text_0.0  1.0   \n",
       "4  50.0  text_0.0  243.0  text_0.0    0.0  0.0      2.6  text_0.0  1.0   \n",
       "\n",
       "      slope      thal  thalach  trestbps  \n",
       "0  text_0.0  text_3.0    111.0     140.0  \n",
       "1  text_1.0  text_3.0    144.0     125.0  \n",
       "2  text_2.0  text_3.0    150.0     130.0  \n",
       "3  text_1.0  text_3.0    132.0     130.0  \n",
       "4  text_1.0  text_3.0    128.0     150.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a quick look at how to reference data from the dictionary\n",
    "mlb_data_hd['train'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the modeling routine\n",
    "\n",
    "#### Defining the search criteria\n",
    "\n",
    "MLBox gives you good control over the modeling algorithms and parameter settings to try.\n",
    "\n",
    "You define a space dictionary and pass it to the **Optimiser** function.\n",
    "\n",
    "Then you pass that Optimiser and the data dictionary to the **Predictor** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "\n",
    "        'ne__numerical_strategy' : {\"space\" : [0, 'mean']},\n",
    "\n",
    "        'ce__strategy' : {\"space\" : [\"label_encoding\", \"random_projection\", \\\n",
    "                                     \"entity_embedding\"]},\n",
    "\n",
    "        'fs__strategy' : {\"space\" : [\"variance\", \"rf_feature_importance\"]},\n",
    "        'fs__threshold': {\"search\" : \"choice\", \"space\" : [0.1, 0.2, 0.3]},\n",
    "\n",
    "        'est__strategy' : {\"space\" : [\"LightGBM\", \"RandomForest\", \"ExtraTrees\",\\\n",
    "                                      \"Linear\"]},\n",
    "        'est__max_depth' : {\"search\" : \"choice\", \"space\" : [5,10,20]},\n",
    "        'est__subsample' : {\"search\" : \"uniform\", \"space\" : [0.6,0.7]}\n",
    "\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      ">>> FEATURE SELECTOR :{'strategy': 'rf_feature_importance', 'threshold': 0.3}\n",
      ">>> ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 20, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      "  0%|          | 0/3 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python3.6/site-packages/mlbox/optimisation/optimiser.py:74: UserWarning: Optimiser will save all your fitted models into directory '../results/joblib'. Please clear it regularly.\n",
      "  +str(self.to_path)+\"/joblib'. Please clear it regularly.\")\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/mlbox/model/classification/classifier.py:92: UserWarning: Invalid parameter for classifier ExtraTrees. Parameter IGNORED. Check the list of available parameters with `classifier.get_params().keys()`\n",
      "  + \". Parameter IGNORED. Check the list of \"\n",
      "\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SCORE : neg_log_loss = -0.3824043364048814\n",
      "VARIANCE : 0.001616917653055161 (fold 1 = -0.38078741875182626, fold 2 = -0.3840212540579366)\n",
      "CPU time: 1.1323630809783936 seconds\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      ">>> FEATURE SELECTOR :{'strategy': 'rf_feature_importance', 'threshold': 0.3}\n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'subsample': 0.609262878266157, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : neg_log_loss = -0.5977422291225285\n",
      "VARIANCE : 0.09576291632355055 (fold 1 = -0.501979312798978, fold 2 = -0.6935051454460791)\n",
      "CPU time: 1.7230215072631836 seconds\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}\n",
      ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.3}\n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'subsample': 0.6958237468998891, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.32s/it, best loss: 0.3824043364048814]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SCORE : neg_log_loss = -0.5858410282390861\n",
      "VARIANCE : 0.10794784848641345 (fold 1 = -0.4778931797526727, fold 2 = -0.6937888767254996)\n",
      "CPU time: 1.4918947219848633 seconds\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.46s/it, best loss: 0.3824043364048814]\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ BEST HYPER-PARAMETERS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "{'ce__strategy': 'label_encoding', 'est__max_depth': 20, 'est__strategy': 'ExtraTrees', 'est__subsample': 0.6933648056361951, 'fs__strategy': 'rf_feature_importance', 'fs__threshold': 0.3, 'ne__numerical_strategy': 'mean'}\n",
      "CPU times: user 4.32 s, sys: 60 ms, total: 4.38 s\n",
      "Wall time: 4.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_hd = Optimiser(to_path = '../results').optimise(space, mlb_data_hd, max_evals = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fitting the pipeline ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python3.6/site-packages/mlbox/model/classification/classifier.py:92: UserWarning: Invalid parameter for classifier ExtraTrees. Parameter IGNORED. Check the list of available parameters with `classifier.get_params().keys()`\n",
      "  + \". Parameter IGNORED. Check the list of \"\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time: 0.6308145523071289 seconds\n",
      "\n",
      "> Feature importances dumped into directory : ../results\n",
      "\n",
      "predicting ...\n",
      "CPU time: 0.034569740295410156 seconds\n",
      "\n",
      "> Overview on predictions : \n",
      "\n",
      "       0.0     1.0  target_predicted\n",
      "1   0.4325  0.5675                 1\n",
      "2   0.3675  0.6325                 1\n",
      "3   0.0350  0.9650                 1\n",
      "4   0.4300  0.5700                 1\n",
      "5   0.4125  0.5875                 1\n",
      "6   0.0675  0.9325                 1\n",
      "7   0.0800  0.9200                 1\n",
      "8   0.0075  0.9925                 1\n",
      "9   0.1025  0.8975                 1\n",
      "10  0.3225  0.6775                 1\n",
      "\n",
      "dumping predictions into directory : ../results ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlbox.prediction.predictor.Predictor at 0x7f1677e4d0b8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predictor(to_path='../results').fit_predict(best_hd,mlb_data_hd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Attribute Information:\n",
    "\n",
    "1) ID number \n",
    "2) Diagnosis (M = malignant, B = benign) \n",
    "3-32) \n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus: \n",
    "\n",
    "a) radius (mean of distances from center to points on the perimeter) \n",
    "b) texture (standard deviation of gray-scale values) \n",
    "c) perimeter \n",
    "d) area \n",
    "e) smoothness (local variation in radius lengths) \n",
    "f) compactness (perimeter^2 / area - 1.0) \n",
    "g) concavity (severity of concave portions of the contour) \n",
    "h) concave points (number of concave portions of the contour) \n",
    "i) symmetry \n",
    "j) fractal dimension (\"coastline approximation\" - 1)\n",
    "'''\n",
    "\n",
    "#column names\n",
    "names = ['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', \\\n",
    "         'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', \\\n",
    "         'concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean', \\\n",
    "         'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', \\\n",
    "         'compactness_se', 'concavity_se', 'concave_points_se', 'symmetry_se', \\\n",
    "         'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', \\\n",
    "         'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', \\\n",
    "         'concave_points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n",
    "\n",
    "#load data from Domino project directory\n",
    "bc_data = pd.read_csv(\"../data/raw/breast_cancer.csv\", index_col=False, header=0, names=names)\n",
    "\n",
    "#create MLBox random samples for train and test\n",
    "bc_data_train = bc_data.sample(frac=0.7, replace=False, random_state=1)\n",
    "bc_data_test = bc_data[~bc_data.isin(bc_data_train)].dropna()\n",
    "bc_data_test_wo_target = bc_data_test.drop('diagnosis', axis=1)\n",
    "\n",
    "bc_data_train.to_csv('../data/processed/bc_data_train.csv', index=False)\n",
    "bc_data_test.to_csv('../data/processed/bc_data_test.csv', index=False)\n",
    "bc_data_test_wo_target.to_csv('../data/processed/bc_data_test_wo_target.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43006131.0</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70354776.0</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>99396622.0</td>\n",
       "      <td>16.02</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.03299</td>\n",
       "      <td>0.03323</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>...</td>\n",
       "      <td>19.19</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>58923522.0</td>\n",
       "      <td>14.54</td>\n",
       "      <td>27.54</td>\n",
       "      <td>96.73</td>\n",
       "      <td>658.8</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.15950</td>\n",
       "      <td>0.16390</td>\n",
       "      <td>0.07364</td>\n",
       "      <td>0.2303</td>\n",
       "      <td>...</td>\n",
       "      <td>17.46</td>\n",
       "      <td>37.13</td>\n",
       "      <td>124.10</td>\n",
       "      <td>943.2</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>0.6577</td>\n",
       "      <td>0.7026</td>\n",
       "      <td>0.17120</td>\n",
       "      <td>0.4218</td>\n",
       "      <td>0.13410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>75772743.0</td>\n",
       "      <td>13.08</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.04568</td>\n",
       "      <td>0.03110</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>...</td>\n",
       "      <td>14.50</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "2   43006131.0        19.69         21.25          130.00     1203.0   \n",
       "7   70354776.0        13.71         20.83           90.20      577.9   \n",
       "10  99396622.0        16.02         23.24          102.70      797.8   \n",
       "15  58923522.0        14.54         27.54           96.73      658.8   \n",
       "20  75772743.0        13.08         15.71           85.63      520.0   \n",
       "\n",
       "    smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n",
       "2           0.10960           0.15990         0.19740              0.12790   \n",
       "7           0.11890           0.16450         0.09366              0.05985   \n",
       "10          0.08206           0.06669         0.03299              0.03323   \n",
       "15          0.11390           0.15950         0.16390              0.07364   \n",
       "20          0.10750           0.12700         0.04568              0.03110   \n",
       "\n",
       "    symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "2          0.2069  ...         23.57          25.53           152.50   \n",
       "7          0.2196  ...         17.06          28.14           110.60   \n",
       "10         0.1528  ...         19.19          33.88           123.80   \n",
       "15         0.2303  ...         17.46          37.13           124.10   \n",
       "20         0.1967  ...         14.50          20.49            96.09   \n",
       "\n",
       "    area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "2       1709.0            0.1444             0.4245           0.4504   \n",
       "7        897.0            0.1654             0.3682           0.2678   \n",
       "10      1150.0            0.1181             0.1551           0.1459   \n",
       "15       943.2            0.1678             0.6577           0.7026   \n",
       "20       630.5            0.1312             0.2776           0.1890   \n",
       "\n",
       "    concave_points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "2                0.24300          0.3613                  0.08758  \n",
       "7                0.15560          0.3196                  0.11510  \n",
       "10               0.09975          0.2948                  0.08452  \n",
       "15               0.17120          0.4218                  0.13410  \n",
       "20               0.07283          0.3184                  0.08183  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_data_test_wo_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the list of paths to your train datasets and test datasets\n",
    "paths_bc = [\"../data/processed/bc_data_train.csv\", \\\n",
    "         \"../data/processed/bc_data_test_wo_target.csv\"]\n",
    "\n",
    "#the name of the target you try to predict (classification or regression)\n",
    "target_bc = \"diagnosis\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reading csv : bc_data_train.csv ...\n",
      "cleaning data ...\n",
      "CPU time: 0.04008889198303223 seconds\n",
      "\n",
      "reading csv : bc_data_test_wo_target.csv ...\n",
      "cleaning data ...\n",
      "CPU time: 0.03135108947753906 seconds\n",
      "\n",
      "> Number of common features : 31\n",
      "\n",
      "gathering and crunching for train and test datasets ...\n",
      "reindexing for train and test datasets ...\n",
      "dropping training duplicates ...\n",
      "dropping constant variables on training set ...\n",
      "\n",
      "> Number of categorical features: 0\n",
      "> Number of numerical features: 31\n",
      "> Number of training samples : 398\n",
      "> Number of test samples : 171\n",
      "\n",
      "> You have no missing values on train set...\n",
      "\n",
      "> Task : classification\n",
      "B    249\n",
      "M    149\n",
      "Name: diagnosis, dtype: int64\n",
      "\n",
      "encoding target ...\n"
     ]
    }
   ],
   "source": [
    "#to read and preprocess your files\n",
    "mlb_data_bc = Reader(sep=\",\", to_path = '../results').train_test_split(paths_bc, target_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing drifts ...\n",
      "CPU time: 0.42563652992248535 seconds\n",
      "\n",
      "> Top 10 drifts\n",
      "\n",
      "('smoothness_se', 0.12057311179701502)\n",
      "('concavity_se', 0.10426929448886013)\n",
      "('perimeter_se', 0.06487189710522512)\n",
      "('texture_mean', 0.06449965284699832)\n",
      "('texture_se', 0.06002275398882251)\n",
      "('symmetry_se', 0.05570224583931971)\n",
      "('perimeter_mean', 0.054076813616646735)\n",
      "('fractal_dimension_mean', 0.04680344265788583)\n",
      "('texture_worst', 0.044321126838020586)\n",
      "('radius_worst', 0.041591679326866915)\n",
      "\n",
      "> Deleted variables : []\n",
      "> Drift coefficients dumped into directory : ../results\n"
     ]
    }
   ],
   "source": [
    "#drop IDs and useless columns\n",
    "mlb_data_bc = Drift_thresholder(to_path='../results').fit_transform(mlb_data_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimise the space and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.3}\n",
      ">>> ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 5, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      "  0%|          | 0/3 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python3.6/site-packages/mlbox/optimisation/optimiser.py:74: UserWarning: Optimiser will save all your fitted models into directory '../results/joblib'. Please clear it regularly.\n",
      "  +str(self.to_path)+\"/joblib'. Please clear it regularly.\")\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/mlbox/model/classification/classifier.py:92: UserWarning: Invalid parameter for classifier ExtraTrees. Parameter IGNORED. Check the list of available parameters with `classifier.get_params().keys()`\n",
      "  + \". Parameter IGNORED. Check the list of \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SCORE : neg_log_loss = -0.16601760645184827\n",
      "VARIANCE : 0.000573284414337516 (fold 1 = -0.16544432203751075, fold 2 = -0.16659089086618578)\n",
      "CPU time: 1.0235469341278076 seconds\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      ">>> FEATURE SELECTOR :{'strategy': 'rf_feature_importance', 'threshold': 0.2}\n",
      ">>> ESTIMATOR :{'strategy': 'RandomForest', 'max_depth': 20, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      " 33%|███▎      | 1/3 [00:01<00:02,  1.03s/it, best loss: 0.16601760645184827]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python3.6/site-packages/mlbox/model/classification/classifier.py:92: UserWarning: Invalid parameter for classifier RandomForest. Parameter IGNORED. Check the list of available parameters with `classifier.get_params().keys()`\n",
      "  + \". Parameter IGNORED. Check the list of \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SCORE : neg_log_loss = -0.15415687465743116\n",
      "VARIANCE : 0.01073353007876457 (fold 1 = -0.1434233445786666, fold 2 = -0.16489040473619573)\n",
      "CPU time: 1.448815107345581 seconds\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}\n",
      ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.1}\n",
      ">>> ESTIMATOR :{'strategy': 'Linear', 'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'ovr', 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "MEAN SCORE : neg_log_loss = -0.6698380210671342\n",
      "VARIANCE : 0.0006972148707411474 (fold 1 = -0.6705352359378753, fold 2 = -0.669140806196393)\n",
      "CPU time: 0.07585716247558594 seconds\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.16it/s, best loss: 0.15415687465743116]\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ BEST HYPER-PARAMETERS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "{'ce__strategy': 'label_encoding', 'est__max_depth': 20, 'est__strategy': 'RandomForest', 'est__subsample': 0.636953884468889, 'fs__strategy': 'rf_feature_importance', 'fs__threshold': 0.2, 'ne__numerical_strategy': 0}\n",
      "CPU times: user 2.49 s, sys: 44 ms, total: 2.54 s\n",
      "Wall time: 2.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python3.6/site-packages/mlbox/model/classification/classifier.py:92: UserWarning: Invalid parameter for classifier Linear. Parameter IGNORED. Check the list of available parameters with `classifier.get_params().keys()`\n",
      "  + \". Parameter IGNORED. Check the list of \"\n",
      "\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_bc = Optimiser(to_path = '../results').optimise(space, mlb_data_bc, max_evals = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fitting the pipeline ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python3.6/site-packages/mlbox/model/classification/classifier.py:92: UserWarning: Invalid parameter for classifier RandomForest. Parameter IGNORED. Check the list of available parameters with `classifier.get_params().keys()`\n",
      "  + \". Parameter IGNORED. Check the list of \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time: 0.7598974704742432 seconds\n",
      "\n",
      "> Feature importances dumped into directory : ../results\n",
      "\n",
      "predicting ...\n",
      "CPU time: 0.028489351272583008 seconds\n",
      "\n",
      "> Overview on predictions : \n",
      "\n",
      "        B       M diagnosis_predicted\n",
      "0  0.0000  1.0000                   M\n",
      "1  0.0725  0.9275                   M\n",
      "2  0.1725  0.8275                   M\n",
      "3  0.0125  0.9875                   M\n",
      "4  1.0000  0.0000                   B\n",
      "5  0.0575  0.9425                   M\n",
      "6  0.0000  1.0000                   M\n",
      "7  0.0150  0.9850                   M\n",
      "8  0.0000  1.0000                   M\n",
      "9  0.2850  0.7150                   M\n",
      "\n",
      "dumping predictions into directory : ../results ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlbox.prediction.predictor.Predictor at 0x7f1677e120f0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predictor(to_path='../results').fit_predict(best_bc,mlb_data_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to Domino Stats File\n",
    "\n",
    "Saving stats to this file [allows Domino to track and trend them in the Experiment Manager](https://support.dominodatalab.com/hc/en-us/articles/204348169-Diagnostic-statistics-with-dominostats-json) when this notebook is run as a batch or scheduled job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this predictions file is the output of the Prediction funtion from above\n",
    "bc_pred = pd.read_csv('../results/diagnosis_predictions.csv')\n",
    "y_bc_pred = bc_pred['diagnosis_predicted']\n",
    "\n",
    "#these are the answers from the file stored in the project\n",
    "bc_test = pd.read_csv('../data/processed/bc_data_test.csv')\n",
    "y_bc_test = bc_test['diagnosis']\n",
    "\n",
    "#this predictions file is the output of the Prediction funtion from above\n",
    "hd_pred = pd.read_csv('../results/target_predictions.csv')\n",
    "y_hd_pred = hd_pred['target_predicted']\n",
    "\n",
    "#these are the answers from the file stored in the project\n",
    "hd_test = pd.read_csv('../data/processed/hd_data_test.csv')\n",
    "y_hd_test = hd_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "hd_acc = sklearn.metrics.accuracy_score(y_hd_test,y_hd_pred)\n",
    "bc_acc = sklearn.metrics.accuracy_score(y_bc_test,y_bc_pred)\n",
    "\n",
    "import json\n",
    "with open('../dominostats.json', 'w') as f:\n",
    "    f.write(json.dumps( {\"HD_ACC\": hd_acc, \"BC_ACC\": bc_acc}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show it here in the notebook as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bc  0.9824561403508771\n",
      "hd  0.7912087912087912\n"
     ]
    }
   ],
   "source": [
    "print('bc ', bc_acc)\n",
    "print('hd ', hd_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
